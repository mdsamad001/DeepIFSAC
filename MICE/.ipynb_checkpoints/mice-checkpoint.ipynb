{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import micegradient as mg\n",
    "# the library is based on https://github.com/AnotherSamWilson/miceforest v2. \n",
    "# They already released v5 which is vastly different so things will differ quite a lot. But still you can check their documentation to get some ideas\n",
    "# to use the library you need to install micegradient. use below command - \n",
    "# pip install -e micegradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient boosting is the most reliable, deep regressor take a lot of time\n",
    "available_estimators = ['LinearRegression', 'GradientBoosting', 'DecisionTree', 'RandomForest', 'DeeRegressor']\n",
    "\n",
    "# initially impute the value using median or random value (selected from the value range) \n",
    "initialization_options = ['median', 'random']\n",
    "\n",
    "# when 0 is mean meatching off, 1 is on (please search predictive mean matching to understand how it works)\n",
    "# it doesn't improve imputation greatly so default is 0 (off)\n",
    "mean_match = [0,1]\n",
    "\n",
    "# number of mice iterations ranges between 1 - 100 (higher numbers can increase runtime drastically)  \n",
    "mice_iterations = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data_missing should be a pandas dataframe\n",
    "training_data_missing = pd.DataFrame()\n",
    "initialization = 'median'\n",
    "estimator_name = 'GradientBoosting'\n",
    "\n",
    "# we can create multiple versions of the imputed datasets by increasing no_of_generated_datasets\n",
    "# if you generate multiple versions you have take the mean from multiple generated version \n",
    "no_of_generated_datasets = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kernel = mg.MultipleImputedKernel(\n",
    "    training_data_missing,\n",
    "    datasets=no_of_generated_datasets,\n",
    "    save_all_iterations=False,\n",
    "    mean_match_candidates=0,\n",
    "    initialization=initialization\n",
    ")\n",
    "\n",
    "kernel.mice(estimator_name, mice_iterations, n_estimators=10)\n",
    "\n",
    "# as you are generating multiple datasets you can access them this way\n",
    "imputed_dataset_1 = kernel.complete_data(0)\n",
    "imputed_dataset_1 = kernel.complete_data(1)\n",
    "\n",
    "# if you set no_of_generated_datasets = 1 access imputed_dataset this way\n",
    "imputed_dataset = kernel.complete_data()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d0ab53687702f15e2269a7a5f443d7849668cd720fb17abf024c8947e466d1d9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "metadata": {
   "interpreter": {
    "hash": "9bf8817141f8e55d4045173966e3c985398a6c03ab0a504d049f97c823e114ec"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
